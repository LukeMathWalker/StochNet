Using SIR_dataset_upgraded_2.npy the following model has achieved the best validation score:

input_tensor = Input(shape=(5, 3))
hidden1 = LSTM(space['LSTM'], kernel_constraint=maxnorm(space['maxnorm']),
               recurrent_constraint=maxnorm(space['maxnorm_1']))(input_tensor)
dropout1 = Dropout(space['Dropout'])(hidden1)
NN_body = Dense(space['LSTM_1'], kernel_constraint=maxnorm(space['maxnorm_2']))(dropout1)
dropout2 = Dropout(space['Dropout_1'])(NN_body)
NN_body = Dense(space['Dense'], kernel_constraint=maxnorm(space['maxnorm_3']))(dropout2)

number_of_components = 2
components = []
for j in range(number_of_components):
    components.append(MultivariateLogNormalOutputLayer(3))
TopModel_obj = MixtureOutputLayer(components)

 NN = StochNeuralNetwork(input_tensor, NN_body, TopModel_obj)

callbacks = [EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='min')]
result = NN.fit(X_train, Y_train,
                batch_size=space['batch_size'],
                epochs=space['epochs'],
                verbose=2,
                callbacks=callbacks,
                validation_data=(X_test, Y_test))

Dense │    Dropout │   Dropout_1 │   LSTM │   LSTM_1 │   batch_size │   epochs │    maxnorm │   maxnorm_1 │   maxnorm_2 │   maxnorm_3 │     val_loss │
╞═════════╪════════════╪═════════════╪════════╪══════════╪══════════════╪══════════╪════════════╪═════════════╪═════════════╪═════════════╪══════════════╡
│     512 │ 0.46178651 │  0.62220663 │     64 │      128 │         1024 │       20 │ 2.22175262 │  2.47433967 │  2.30359363 │  1.87423252 │ -13.86716309
